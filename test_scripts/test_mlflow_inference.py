"""
test_mlflow_inference.py

ê¸°ëŠ¥: (1) RUN_IDë¡œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ(ë˜ëŠ” ìµœì‹  RUN ìë™ ì„ íƒ),
     (2) Influxì—ì„œ ìµœê·¼ ë°ì´í„° ì¡°íšŒ, (3) ê°„ë‹¨ ì „ì²˜ë¦¬,
     (4) ëª¨ë¸ ë¡œë“œ/ì¶”ë¡ , (5) ì½˜ì†”ì— ê²°ê³¼/ì¤‘ê°„ê°’ ì¶œë ¥

í™˜ê²½ë³€ìˆ˜(ê¶Œì¥):
  - MLFLOW_TRACKING_URI: ì˜ˆ) http://10.250.109.206:5000
  - RUN_ID: ì§€ì • ì‹œ í•´ë‹¹ RUN ì‚¬ìš©, ë¯¸ì§€ì • ì‹œ ìµœì‹  RUN ìë™ ì„ íƒ
  - MLFLOW_EXPERIMENT_NAME: ìµœì‹  RUN ìë™ ì„ íƒ ì‹œ í•„ìš” (ì˜ˆ: urea_gp_prod)

  - MODEL_LOCAL_DIR: ìˆ˜ë™ ë³µì‚¬í•œ ëª¨ë¸ ë””ë ‰í† ë¦¬ ì§€ì • ì‹œ MLflow ë‹¤ìš´ë¡œë“œ ìš°íšŒ
    (ë¯¸ì§€ì • ì‹œ, í”„ë¡œì íŠ¸ ë‚´ mlflow_artifacts/<RUN_ID>/urea_gp_model ê²½ë¡œ ìë™ íƒìƒ‰)

  - START_TIME (UTC): ì ˆëŒ€ ì‹œì‘ì‹œê°(UTC) ì§€ì • ì‹œ ì‚¬ìš© (ì˜ˆ: "2025-08-27 00:00:01")
    - ì§€ì • ì‹œ: [START_TIME, START_TIME + INFLUX_WINDOW] êµ¬ê°„ë§Œ ì¡°íšŒ (UTC)
  - START_TIME_KST: ì ˆëŒ€ ì‹œì‘ì‹œê°(KST) ì§€ì • ì‹œ ì‚¬ìš© (ì˜ˆ: "2025-08-27 09:00:01")
    - ì§€ì • ì‹œ: [START_TIME_KST, START_TIME_KST + INFLUX_WINDOW] êµ¬ê°„ë§Œ ì¡°íšŒ (KST)
    - ë¯¸ì§€ì • ì‹œ: [now() - INFLUX_WINDOW, now()] êµ¬ê°„ ì¡°íšŒ

  - INFLUX_HOST (ê¸°ë³¸: 10.238.27.132)
  - INFLUX_PORT (ê¸°ë³¸: 8086)
  - INFLUX_USERNAME (ê¸°ë³¸: read_user)
  - INFLUX_PASSWORD (ê¸°ë³¸: !Skepinfluxuser25)
  - INFLUX_DB (ê¸°ë³¸: SRS1)
  - INFLUX_MEASUREMENT (ê¸°ë³¸: SRS1)
  - INFLUX_WINDOW (ê¸°ë³¸: 10m)
  - INFLUX_LIMIT (ê¸°ë³¸: 120)
"""

import os
import sys
from pathlib import Path
from typing import Optional, List

# Ensure project root is on sys.path regardless of current working directory
THIS_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = THIS_DIR.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

import numpy as np
import pandas as pd
import joblib

from influxdb import InfluxDBClient
import mlflow
import time
import requests

# ìƒˆë¡œìš´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ import
from config.column_config import ColumnConfig
from config.preprocessing_config import (
    InferPreprocessingConfig,
    LGBMInferPreprocessingConfig,
)
from config.model_config import GPModelConfig, LGBMModelConfig
from config.optimization_config import OptimizationConfig
from config.rule_config import RuleConfig
from src.data_processing.preprocessor import Preprocessor, LGBMFeaturePreprocessor
from src.models.gaussian_process import GaussianProcessNOxModel
from src.models.lgbm import LGBMNOxModel
from src.optimization.pump_optimizer import PumpOptimizer
from src.optimization.pump_hz_adjuster import LGBMPumpHzAdjuster
from utils.logger import LoggerConfig

# pandas ì¶œë ¥ ì„¤ì •: ëª¨ë“  ì»¬ëŸ¼ í‘œì‹œ
pd.set_option("display.max_columns", None)
pd.set_option("display.width", None)
pd.set_option("display.max_colwidth", None)

# GP ì œì–´ ëª¨ë¸ ì…ë ¥ ìš”êµ¬ ì»¬ëŸ¼(8ê°œ) - ColumnConfigì™€ ë§¤í•‘
REQUIRED_COLUMNS: List[str] = [
    "_time_gateway",  # col_datetime
    "BR1_EO_O2_A",  # col_o2
    "SNR_PMP_UW_S_1",  # col_hz
    "ICF_CCS_FG_T_1",  # col_inner_temp
    "ICF_SCS_FG_T_1",  # col_outer_temp
    "ICF_TMS_NOX_A",  # col_nox
    "ACC_SNR_AI_1A",  # col_ai
    "ACT_STATUS",  # col_act_status
]


def get_env(name: str, default: Optional[str] = None) -> str:
    v = os.environ.get(name)
    return v if v is not None else ("" if default is None else str(default))


def setup_preprocessing_config() -> tuple[
    ColumnConfig,
    InferPreprocessingConfig,
    LGBMInferPreprocessingConfig,
    Preprocessor,
    LGBMFeaturePreprocessor,
    GPModelConfig,
    LGBMModelConfig,
    GaussianProcessNOxModel,
    LGBMNOxModel,
    OptimizationConfig,
    PumpOptimizer,
    LGBMPumpHzAdjuster,
]:
    """ì „ì²˜ë¦¬ ì„¤ì • ë° GP/LGBM ëª¨ë¸, PumpOptimizer ì´ˆê¸°í™”"""
    # ColumnConfig ì´ˆê¸°í™” (SRS1 í”„ë¦¬ì…‹ ì ìš©)
    cc = ColumnConfig(plant_code="SRS1")

    # InferPreprocessingConfig ì´ˆê¸°í™”
    infer_cfg = InferPreprocessingConfig(
        column_config=cc,
        plant_code="SRS1",
        resample_sec=5,  # 5ì´ˆ ê°„ê²©
        ffill_limit_sec=600,  # 10ë¶„ ì´ë‚´ ffill
    )

    # LGBMInferPreprocessingConfig ì´ˆê¸°í™”
    lgbm_infer_cfg = LGBMInferPreprocessingConfig(column_config=cc)

    # Preprocessor ì´ˆê¸°í™”
    preprocessor = Preprocessor(
        column_config=cc,
        prep_infer_cfg=infer_cfg,
    )

    # LGBMFeaturePreprocessor ì´ˆê¸°í™”
    lgbm_preprocessor = LGBMFeaturePreprocessor(lgbm_infer_cfg)

    # GPModelConfig ì´ˆê¸°í™”
    gp_cfg = GPModelConfig(
        column_config=cc,
        plant_code="SRS1",
        logger_cfg=LoggerConfig(name="GPModel", level=20),  # INFO ë ˆë²¨
    )

    # LGBMModelConfig ì´ˆê¸°í™” [0910] column_configì™€ plant_code ëª¨ë‘ ì‚­ì œ
    lgbm_cfg = LGBMModelConfig(
        lgbm_feature_columns_original=cc.lgbm_feature_columns,
        lgbm_feature_columns_summary=[],  # ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸
        # native_model_path=lgbm_model_path,  # [0910] ì£¼ì„ ì²˜ë¦¬
        model_path="mlflow_artifacts/8df2907f144a4dcd80fe0d834be77f65/urea_gp_model/lgbm_model.joblib",
        logger_cfg=LoggerConfig(name="LGBMModel", level=20),
    )

    # GaussianProcessNOxModel ì´ˆê¸°í™”
    gp_model = GaussianProcessNOxModel(
        column_config=cc,
        model_config=gp_cfg,
    )

    # LGBMNOxModel ì´ˆê¸°í™”
    # [0910] ìˆ˜ì • (optimize_pump.py ë°©ì‹)
    lgbm_model = LGBMNOxModel(
        column_config=cc,  # ì¶”ê°€
        model_config=lgbm_cfg,
    )

    # OptimizationConfig ì´ˆê¸°í™” (ê¸°ë³¸ê°’ ì‚¬ìš©)
    opt_cfg = OptimizationConfig()

    # RuleConfig ì´ˆê¸°í™”
    rule_cfg = RuleConfig()

    # PumpOptimizer ì´ˆê¸°í™”
    pump_optimizer = PumpOptimizer(
        model=gp_model,
        column_config=cc,
        opt_config=opt_cfg,
        rule_config=rule_cfg,
    )

    # LGBMPumpHzAdjuster ì´ˆê¸°í™”
    lgbm_adjuster = LGBMPumpHzAdjuster(
        column_config=cc,
        model_config=lgbm_cfg,
        rule_config=rule_cfg,
        optimization_config=opt_cfg,
    )

    return (
        cc,
        infer_cfg,
        lgbm_infer_cfg,
        preprocessor,
        lgbm_preprocessor,
        gp_cfg,
        lgbm_cfg,
        gp_model,
        lgbm_model,
        opt_cfg,
        pump_optimizer,
        lgbm_adjuster,
    )


def select_run_id() -> str:
    run_id = os.environ.get("RUN_ID")
    if run_id:
        print(f"[INFO] í™˜ê²½ë³€ìˆ˜ RUN_ID ì§€ì •ë¨: {run_id}")
        return run_id

    # ê¸°ë³¸ ì‹¤í—˜ëª…ê³¼ Run Name ì ‘ë‘ì–´
    experiment = os.environ.get("MLFLOW_EXPERIMENT_NAME", "skep-urea")
    run_name_prefix = os.environ.get("MLFLOW_RUN_NAME_PREFIX", "urea-SRS1-")

    # Run Nameìœ¼ë¡œ í•„í„°ë§í•˜ì—¬ ìµœì‹  RUN ì„ íƒ
    filter_string = f"tags.mlflow.runName LIKE '{run_name_prefix}%'"

    print(f"[INFO] ìµœì‹  RUN ìë™ ì„ íƒ - ì‹¤í—˜ëª…: {experiment}")
    print(f"[INFO] í•„í„°: {filter_string}")
    exp = mlflow.get_experiment_by_name(experiment)
    if exp is None:
        raise ValueError(f"Experiment '{experiment}' not found")
    runs = mlflow.search_runs(
        experiment_ids=[exp.experiment_id],
        filter_string=filter_string,
        order_by=["start_time DESC"],
        max_results=1,
    )
    if runs.empty:
        raise ValueError(
            f"No runs found in experiment '{experiment}' with filter '{filter_string}'"
        )
    return runs.iloc[0]["run_id"]


def download_model(run_id: str, model_name: str = "urea_gp_model") -> Path:
    # 0) ë¡œì»¬ ê²½ë¡œ ì˜¤ë²„ë¼ì´ë“œ(ë¬¸ì œì‹œ ìˆ˜ë™ ë°°í¬ íŒŒì¼ ì‚¬ìš©)
    override = os.environ.get("MODEL_LOCAL_DIR")
    if override:
        p = Path(override)
        if p.exists() and any(p.rglob("*")):
            print(f"[INFO] ë¡œì»¬ ëª¨ë¸ ê²½ë¡œ ì‚¬ìš©(MODEL_LOCAL_DIR): {p}")
            return p

    # 0-1) í”„ë¡œì íŠ¸ ë‚´ ìˆ˜ë™ ë³µì‚¬ë³¸ ìë™ íƒìƒ‰
    # ìš°ì„ ìˆœìœ„: mlflow_artifacts/<RUN_ID>/urea_gp_model â†’ mlflow_artifacts/<RUN_ID>/artifacts/urea_gp_model â†’ mlflow_artifacts/<RUN_ID>
    local_candidates = [
        PROJECT_ROOT / "mlflow_artifacts" / run_id / model_name,
        PROJECT_ROOT / "mlflow_artifacts" / run_id / "artifacts" / model_name,
        PROJECT_ROOT / "mlflow_artifacts" / run_id,
    ]
    for cand in local_candidates:
        if cand.exists() and any(cand.rglob("*")):
            print(f"[INFO] ë¡œì»¬ ëª¨ë¸ ê²½ë¡œ ìë™ ê°ì§€: {cand}")
            return cand

    dst = Path("/tmp/mlflow_models") / f"{run_id}_{model_name}"
    # ìºì‹œ ì¡´ì¬ ì‹œ ì¬ì‚¬ìš©
    if dst.exists() and any(dst.rglob("*")):
        print(f"[INFO] ìºì‹œëœ ëª¨ë¸ ì‚¬ìš©: {dst}")
        return dst

    print(f"[INFO] ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘: run_id={run_id}, artifact={model_name}")
    t0 = time.time()
    path = mlflow.artifacts.download_artifacts(
        artifact_uri=f"runs:/{run_id}/{model_name}",
        dst_path=str(dst),
    )
    elapsed = time.time() - t0
    print(f"[INFO] ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ({elapsed:.1f}s): {path}")
    print("[INFO] í¬í•¨ íŒŒì¼ ëª©ë¡(ìµœëŒ€ 10ê°œ):")
    cnt = 0
    for p in Path(path).rglob("*"):
        print(" -", p)
        cnt += 1
        if cnt >= 10:
            print(" - ...")
            break
    return path


def test_mlflow_connection() -> None:
    """Quick MLflow connectivity test with short timeouts.

    - GET tracking root (5s)
    - POST experiments/list (5s)
    - If RUN_ID is set, POST runs/get to print artifact_uri (5s)
    """
    tracking = os.environ.get("MLFLOW_TRACKING_URI")
    print("\nğŸ§ª MLflow ì—°ê²° í…ŒìŠ¤íŠ¸")
    if not tracking:
        print("[WARN] MLFLOW_TRACKING_URI ë¯¸ì„¤ì • â†’ ì—°ê²° í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€")
        return

    base = tracking.rstrip("/")
    try:
        r = requests.get(base, timeout=5)
        print(f"  â†³ GET {base} â†’ HTTP {r.status_code}")
    except Exception as e:
        print(f"âŒ GET {base} ì‹¤íŒ¨: {e}")

    try:
        url = f"{base}/api/2.0/mlflow/experiments/list"
        r = requests.post(url, json={}, timeout=5)
        print(f"  â†³ POST /experiments/list â†’ HTTP {r.status_code}")
    except Exception as e:
        print(f"âŒ POST /experiments/list ì‹¤íŒ¨: {e}")

    run_id = os.environ.get("RUN_ID")
    if run_id:
        try:
            url = f"{base}/api/2.0/mlflow/runs/get"
            r = requests.post(url, json={"run_id": run_id}, timeout=5)
            if r.ok:
                data = r.json()
                art = data.get("run", {}).get("info", {}).get("artifact_uri")
                print(f"ğŸ“¦ run.artifact_uri: {art}")
            else:
                print(f"âš ï¸ runs/get HTTP {r.status_code}")
        except Exception as e:
            print(f"âŒ POST /runs/get ì‹¤íŒ¨: {e}")
    else:
        print("â„¹ï¸ RUN_ID ë¯¸ì„¤ì • â†’ runs/get ìƒëµ")


def pick_model_file(root: Path) -> Path:
    candidates: List[Path] = [*root.rglob("*.joblib"), *root.rglob("*.pkl")]
    if not candidates:
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {root}")
    print("[INFO] ë¡œë“œ í›„ë³´:")
    for c in candidates:
        print(" -", c)
    return candidates[0]


def query_recent_influx() -> pd.DataFrame:
    host = get_env("INFLUX_HOST", "10.238.27.132")
    port = int(get_env("INFLUX_PORT", "8086"))
    username = get_env("INFLUX_USERNAME", "read_user")
    password = get_env("INFLUX_PASSWORD", "!Skepinfluxuser25")
    database = get_env("INFLUX_DB", "SRS1")
    measurement = get_env("INFLUX_MEASUREMENT", "SRS1")
    # ìš”êµ¬ì‚¬í•­: ìµœê·¼ 10ë¶„ ì¡°íšŒ (5ì´ˆ ê°„ê²© â†’ 120ê°œ) ë˜ëŠ” ì ˆëŒ€ ì‹œì‘ì‹œê° ê¸°ë°˜ ì¡°íšŒ
    window = get_env("INFLUX_WINDOW", "10m")
    limit = int(get_env("INFLUX_LIMIT", "200"))
    start_time_kst = get_env("START_TIME_KST", "").strip()
    start_time_utc = get_env("START_TIME", "").strip()

    client = InfluxDBClient(
        host=host,
        port=port,
        username=username,
        password=password,
        database=database,
        timeout=30,
    )

    # ì ˆëŒ€ ì‹œì‘ì‹œê°ì´ ì§€ì •ë˜ë©´ í•´ë‹¹ êµ¬ê°„ë§Œ ì¡°íšŒ (ìš°ì„ ìˆœìœ„: START_TIME(UTC) > START_TIME_KST)
    if start_time_utc:
        # UTC ê¸°ì¤€ ê³ ì • êµ¬ê°„
        start_utc_dt = pd.to_datetime(start_time_utc, utc=True, errors="coerce")
        # INFLUX_WINDOW íŒŒì‹± (s/m)
        w = window.lower().strip()
        secs = 600  # 10ë¶„ ê¸°ë³¸ê°’
        if w.endswith("s"):
            secs = int(w[:-1] or 0)
        elif w.endswith("m"):
            secs = int(w[:-1] or 0) * 60
        else:
            # fallback: 10m
            secs = 600
        end_utc_dt = start_utc_dt + pd.to_timedelta(max(secs - 1, 0), unit="s")
        start_utc = start_utc_dt.strftime("%Y-%m-%dT%H:%M:%SZ")
        end_utc = end_utc_dt.strftime("%Y-%m-%dT%H:%M:%SZ")
        print(
            f"[INFO] ì ˆëŒ€ ì‹œê°„ ì¡°íšŒ(UTC): {start_utc_dt} ~ {end_utc_dt} (window={window})"
        )
        query = (
            f'\nSELECT * FROM "{measurement}" '
            f"WHERE time >= '{start_utc}' AND time <= '{end_utc}' "
            f"ORDER BY time ASC LIMIT {limit}\n"
        )
    elif start_time_kst:
        try:
            start_kst = pd.to_datetime(start_time_kst).tz_localize("Asia/Seoul")
        except Exception:
            start_kst = pd.to_datetime(start_time_kst).tz_convert("Asia/Seoul")
        # INFLUX_WINDOW íŒŒì‹± (s/m)
        w = window.lower().strip()
        secs = 600  # 10ë¶„ ê¸°ë³¸ê°’
        if w.endswith("s"):
            secs = int(w[:-1] or 0)
        elif w.endswith("m"):
            secs = int(w[:-1] or 0) * 60
        else:
            # fallback: 10m
            secs = 600
        # ì¢…ë£Œ ì‹œì  í¬í•¨ ì¡°ê±´(<=)ì´ë¯€ë¡œ ì •í™•íˆ 10ë¶„ êµ¬ê°„ì„ ë§Œë“¤ê¸° ìœ„í•´ 1ì´ˆ ê°ì†Œ
        end_kst = start_kst + pd.to_timedelta(max(secs - 1, 0), unit="s")
        start_utc = start_kst.tz_convert("UTC").strftime("%Y-%m-%dT%H:%M:%SZ")
        end_utc = end_kst.tz_convert("UTC").strftime("%Y-%m-%dT%H:%M:%SZ")
        print(f"[INFO] ì ˆëŒ€ ì‹œê°„ ì¡°íšŒ(KST): {start_kst} ~ {end_kst} (window={window})")
        query = (
            f'\nSELECT * FROM "{measurement}" '
            f"WHERE time >= '{start_utc}' AND time <= '{end_utc}' "
            f"ORDER BY time ASC LIMIT {limit}\n"
        )
    else:
        query = (
            f'\nSELECT * FROM "{measurement}" '
            f"WHERE time >= now() - {window} AND time <= now() "
            f"ORDER BY time DESC LIMIT {limit}\n"
        )
    print("ğŸ” Influx ì¿¼ë¦¬:", query)
    result = client.query(query)
    points = list(result.get_points()) if result else []
    print(f"ğŸ“Š ì¡°íšŒ í¬ì¸íŠ¸ ìˆ˜: {len(points)}")

    if not points:
        raise RuntimeError("ìµœê·¼ êµ¬ê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì‹œê°„ì°½/ì¸¡ì •ê°’ì„ ì¡°ì •í•˜ì„¸ìš”.")

    df = pd.DataFrame(points)
    print("ğŸ—‚ï¸ ì›ë³¸ ë°ì´í„°í”„ë ˆì„:", df.shape)
    # ì£¼ ê´€ì‹¬ ì»¬ëŸ¼ë§Œ ë¯¸ë¦¬ë³´ê¸°: REQUIRED_COLUMNS + time
    preview_cols = [c for c in ["time", *REQUIRED_COLUMNS] if c in df.columns]
    try:
        print("ğŸ” ì›ë³¸ InfluxDB ë°ì´í„° (ì²˜ìŒ 5ê°œ í–‰):")
        print(df[preview_cols].head(5) if preview_cols else df.head(5))
        print("ğŸ” ì›ë³¸ InfluxDB ë°ì´í„° í†µê³„:")
        if preview_cols:
            print(df[preview_cols].describe())
        else:
            print(df.describe())
    except Exception:
        print("ğŸ” ì›ë³¸ InfluxDB ë°ì´í„° (ì²˜ë¦¬ ì‹¤íŒ¨):")
        print(df.head(5))
    return df


def aggregate_10min_to_5s(
    df: pd.DataFrame, preprocessor: Preprocessor, cc: ColumnConfig
) -> pd.DataFrame:
    """ìµœê·¼ 10ë¶„ ë°ì´í„°ë¥¼ 5ì´ˆ ìœˆë„ìš°ë¡œ ìš”ì•½í•˜ì—¬ 120í–‰ ë°˜í™˜.

    ìƒˆë¡œìš´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ í™œìš©í•˜ì—¬ ffill ë³´ê°„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    - ì„¼ì„œ ì»¬ëŸ¼: 5ì´ˆ í‰ê· 
    - *_status ì»¬ëŸ¼: ê° ìœˆë„ìš°ì˜ ë§ˆì§€ë§‰ ê°’
    - _time_gateway: ê° ìœˆë„ìš°ì˜ ê²½ê³„ ì‹œê°(ì˜¤ë¥¸ìª½ ë¼ë²¨)
    """
    if "time" not in df.columns:
        raise KeyError("Influx ì‘ë‹µì— 'time' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # 1) InfluxDB ì»¬ëŸ¼ëª…ì„ ColumnConfig ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë§¤í•‘
    df_mapped = df.copy()
    df_mapped[cc.col_datetime] = pd.to_datetime(df["time"], utc=True, errors="coerce")

    # ì»¬ëŸ¼ëª… ë§¤í•‘ (InfluxDB â†’ ColumnConfig)
    column_mapping = {
        "BR1_EO_O2_A": cc.col_o2,
        "SNR_PMP_UW_S_1": cc.col_hz,
        "ICF_CCS_FG_T_1": cc.col_inner_temp,
        "ICF_SCS_FG_T_1": cc.col_outer_temp,
        "ICF_TMS_NOX_A": cc.col_nox,
        "ACC_SNR_AI_1A": cc.col_ai,
        "ACT_STATUS": cc.col_act_status,
    }

    for influx_col, config_col in column_mapping.items():
        if influx_col in df.columns:
            df_mapped[config_col] = df[influx_col]

    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
    required_cols = [cc.col_datetime] + list(column_mapping.values())
    df_mapped = df_mapped[required_cols].dropna(subset=[cc.col_datetime])

    print(f"ğŸ”„ ì»¬ëŸ¼ ë§¤í•‘ ì™„ë£Œ: {df_mapped.shape}")
    print(f"ğŸ“‹ ë§¤í•‘ëœ ì»¬ëŸ¼: {list(df_mapped.columns)}")

    # 2) 5ì´ˆ ìœˆë„ìš° ìš”ì•½ (ì„¼ì„œ: í‰ê· , ìƒíƒœ: ë§ˆì§€ë§‰ê°’)
    df_mapped = df_mapped.set_index(cc.col_datetime).sort_index()

    # ì„¼ì„œ/ìƒíƒœ ì»¬ëŸ¼ êµ¬ë¶„
    status_cols = [cc.col_act_status]
    sensor_cols = [c for c in df_mapped.columns if c not in status_cols]

    # 5ì´ˆ ìœˆë„ìš° ìš”ì•½
    df_mean = (
        df_mapped[sensor_cols].resample("5s", label="right", closed="right").mean()
    )
    df_last = (
        df_mapped[status_cols].resample("5s", label="right", closed="right").last()
    )

    # ë³´ê°„ ì „ ìš”ì•½ ì¶œë ¥
    agg_pre = pd.concat([df_mean, df_last], axis=1)
    agg_pre.index.name = cc.col_datetime
    agg_pre = agg_pre.reset_index()
    agg_pre = agg_pre.sort_values(cc.col_datetime).head(120)
    print("ğŸ§¾ 5ì´ˆ ìœˆë„ìš° ìš”ì•½(ë³´ê°„ ì „, UTC):")
    print(agg_pre.head(4))

    # 3) preprocessor.pyì˜ make_infer_ffill í™œìš©
    print("ğŸ”§ preprocessor.py make_infer_ffill ì ìš© ì¤‘...")
    agg_processed = preprocessor.make_infer_ffill(
        agg_pre,
        require_full_index=False,  # ì´ë¯¸ 5ì´ˆ ê°„ê²©ìœ¼ë¡œ ìš”ì•½ë¨
        logger_cfg=LoggerConfig(name="MLflowInference", level=20),  # INFO ë ˆë²¨
    )

    # 4) ìµœì¢… ê²°ê³¼ ì •ë¦¬
    agg_processed = agg_processed.sort_values(cc.col_datetime).head(120)

    # ì»¬ëŸ¼ëª…ì„ ì›ë˜ REQUIRED_COLUMNSë¡œ ë˜ëŒë¦¬ê¸°
    reverse_mapping = {v: k for k, v in column_mapping.items()}
    reverse_mapping[cc.col_datetime] = "_time_gateway"

    agg_final = agg_processed.rename(columns=reverse_mapping)

    # ì—´ ìˆœì„œ ì •ë ¬: REQUIRED_COLUMNS ìˆœì„œ ìœ ì§€(ì¡´ì¬í•˜ëŠ” ê²ƒë§Œ)
    ordered_cols = [c for c in REQUIRED_COLUMNS if c in agg_final.columns]
    agg_final = agg_final[ordered_cols]

    print("ğŸ§¾ 5ì´ˆ ìœˆë„ìš° ìš”ì•½(ë³´ê°„ í›„, UTC):")
    print(agg_final.head(4))

    return agg_final


def main() -> None:
    print("ğŸš€" + "=" * 58)
    print("ğŸš€ GP ëª¨ë¸ ê¸°ë°˜ ì‹¤ì‹œê°„ ì¶”ë¡  ë° Hz ì¶”ì²œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("ğŸš€" + "=" * 58)

    # 0) ì „ì²˜ë¦¬ ì„¤ì • ë° GP/LGBM ëª¨ë¸, PumpOptimizer ì´ˆê¸°í™”
    print("âš™ï¸ ì „ì²˜ë¦¬ ì„¤ì • ë° GP/LGBM ëª¨ë¸, PumpOptimizer ì´ˆê¸°í™” ì¤‘...")
    (
        cc,
        infer_cfg,
        lgbm_infer_cfg,
        preprocessor,
        lgbm_preprocessor,
        gp_cfg,
        lgbm_cfg,
        gp_model,
        lgbm_model,
        opt_cfg,
        pump_optimizer,
        lgbm_adjuster,
    ) = setup_preprocessing_config()
    print(f"âœ… GP ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ: {gp_model.model_config.plant_code}")
    print(
        f"â„¹ï¸ LGBM ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ: {lgbm_model.model_config.__class__.__name__} (ë¹„í™œì„±í™”)"
    )
    print(f"âœ… PumpOptimizer ì´ˆê¸°í™” ì™„ë£Œ")
    print(f"â„¹ï¸ LGBM Adjuster ì´ˆê¸°í™” ì™„ë£Œ (ë¹„í™œì„±í™”)")

    tracking_uri = os.environ.get("MLFLOW_TRACKING_URI")
    if tracking_uri:
        print(f"ğŸ”— MLFLOW_TRACKING_URI: {tracking_uri}")
    else:
        print(
            "âš ï¸ MLFLOW_TRACKING_URIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. mlflow ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
        )

    # 1) RUN ì„ íƒ
    if tracking_uri:
        mlflow.set_tracking_uri(tracking_uri)
    # ì—°ê²° ì‚¬ì „ ì ê²€
    test_mlflow_connection()
    run_id = select_run_id()
    print(f"ğŸ·ï¸ ì‚¬ìš© RUN_ID: {run_id}")

    # 2) GP ëª¨ë¸ ë¡œë“œ (ê¸°ì¡´ MLflow ëª¨ë¸ ëŒ€ì‹ )
    model_file = f"mlflow_artifacts/{run_id}/urea_gp_model/gp_model.joblib"
    if not os.path.exists(model_file):
        # ëŒ€ì•ˆ ê²½ë¡œ ì‹œë„
        model_file = f"mlflow_artifacts/{run_id}/gp_model.joblib"
        if not os.path.exists(model_file):
            raise FileNotFoundError(f"GP ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_file}")

    # GP ëª¨ë¸ ë¡œë“œ
    gp_model.load(model_file)
    print(f"âœ… GP ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_file}")

    # ëª¨ë¸ ì •ë³´ ì¶œë ¥
    model_info = gp_model.get_model_info()
    print(
        f"ğŸ“Š GP ëª¨ë¸ ì •ë³´: {model_info['status']}, í•™ìŠµ ìƒ˜í”Œ: {model_info.get('n_train', 'N/A')}"
    )

    # GP ëª¨ë¸ ìƒì„¸ ì •ë³´ ì¶œë ¥
    print("ğŸ” GP ëª¨ë¸ ìƒì„¸ ì •ë³´:")
    if hasattr(gp_model, "model") and gp_model.model is not None:
        print(f"  - ëª¨ë¸ íƒ€ì…: {type(gp_model.model)}")
        print(f"  - ì»¤ë„: {gp_model.model.kernel_}")
        print(f"  - ì•ŒíŒŒ: {gp_model.model.alpha_}")
        print(
            f"  - í•™ìŠµ ë°ì´í„° ìˆ˜: {gp_model.model.X_train_.shape if hasattr(gp_model.model, 'X_train_') else 'N/A'}"
        )
    else:
        print("  - ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ!")

    # 3) LGBM ëª¨ë¸ ë¡œë“œ (ë””ë²„ê¹… ëª¨ë“œì—ì„œëŠ” ë¹„í™œì„±í™”)
    lgbm_model_path = os.environ.get(
        "LGBM_MODEL_PATH", f"mlflow_artifacts/{run_id}/urea_gp_model/lgbm_model.txt"
    )
    # if not os.path.exists(lgbm_model_path):
    #     raise FileNotFoundError(f"LGBM ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {lgbm_model_path}")

    # # LGBM ëª¨ë¸ ë¡œë“œ
    # lgbm_model.load(lgbm_model_path)
    print(f"â„¹ï¸ LGBM ëª¨ë¸ ë¡œë“œ ë¹„í™œì„±í™” (ë””ë²„ê¹… ëª¨ë“œ): {lgbm_model_path}")

    # 4) Influx ìµœê·¼ ë°ì´í„° ì¡°íšŒ
    df = query_recent_influx()

    # 5) 5ì´ˆ ìœˆë„ìš° ìš”ì•½(ìµœê·¼ 10ë¶„ â†’ 120í–‰) - ìƒˆë¡œìš´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í™œìš©
    agg = aggregate_10min_to_5s(df, preprocessor, cc)
    print("ğŸ§¾ ëª¨ë¸ ì…ë ¥ìš© ìš”ì•½(ì—´ ìˆœì„œ ê³ ì •):", agg.shape)
    print(agg)

    # 6) ëª¨ë¸ ì…ë ¥í–‰ ë§Œë“¤ê¸°: ColumnConfigì˜ gp_feature_columns í™œìš©
    feature_cols = cc.gp_feature_columns  # [col_hz, col_o2, col_temp]
    # InfluxDB ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€í™˜
    influx_feature_cols = ["SNR_PMP_UW_S_1", "BR1_EO_O2_A", "ICF_CCS_FG_T_1"]

    missing_feat = [c for c in influx_feature_cols if c not in agg.columns]
    if missing_feat:
        raise KeyError(f"ëª¨ë¸ ì…ë ¥ í”¼ì²˜ ëˆ„ë½: {missing_feat}")

    X_all = agg[influx_feature_cols]
    valid_mask = ~X_all.isna().any(axis=1)
    invalid_times = agg.loc[~valid_mask, "_time_gateway"].tolist()
    if invalid_times:
        print(
            f"[WARN] ê²°ì¸¡ì¹˜ë¡œ ì¸í•´ ì˜ˆì¸¡ì—ì„œ ì œì™¸ëœ 5ì´ˆ êµ¬ê°„: {len(invalid_times)}ê±´ â†’ {invalid_times}"
        )

    X = X_all.loc[valid_mask].to_numpy(dtype=float)
    valid_times = agg.loc[valid_mask, "_time_gateway"].tolist()
    print("ğŸ§® ì˜ˆì¸¡ ì…ë ¥ ë°°ì—´ í˜•íƒœ:", X.shape)
    print(f"ğŸ“‹ í”¼ì²˜ ì»¬ëŸ¼: {influx_feature_cols}")
    print("ğŸ” GP ëª¨ë¸ ì…ë ¥ ë°ì´í„° (ì²˜ìŒ 5ê°œ í–‰):")
    print(X[:5])
    print("ğŸ” GP ëª¨ë¸ ì…ë ¥ ë°ì´í„° í†µê³„:")
    print(f"  - í‰ê· : {X.mean(axis=0)}")
    print(f"  - í‘œì¤€í¸ì°¨: {X.std(axis=0)}")
    print(f"  - ìµœì†Ÿê°’: {X.min(axis=0)}")
    print(f"  - ìµœëŒ“ê°’: {X.max(axis=0)}")

    # 6) GP ëª¨ë¸ ì˜ˆì¸¡ ë° Hz ì¶”ì²œ: ê° 5ì´ˆ ìœˆë„ìš°ì— ëŒ€í•´ NOx ì˜ˆì¸¡ ë° Hz ì¶”ì²œ
    if len(X) > 0:
        print("ğŸ§  GP ëª¨ë¸ ì˜ˆì¸¡ ë° Hz ì¶”ì²œ ì‹œì‘...")

        # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì €ì¥í•  DataFrame ì¤€ë¹„
        agg_with_recommendations = agg.copy()

        # GP ëª¨ë¸ ì¼ê´„ ì˜ˆì¸¡ (120ê°œ í–‰)
        print("ğŸ“Š GP ëª¨ë¸ ì¼ê´„ ì˜ˆì¸¡ ì¤‘...")
        gp_pred_mean, gp_pred_std = gp_model.predict(X, return_std=True)
        gp_pred_ucb = gp_pred_mean + 1.96 * gp_pred_std  # 95% ì‹ ë¢°êµ¬ê°„ ìƒí•œ

        # ê° ìœ íš¨í•œ ì‹œì ì— ëŒ€í•´ Hz ì¶”ì²œ ìˆ˜í–‰
        for i, (t, x_row) in enumerate(zip(valid_times, X)):
            if i < 5:  # ì²˜ìŒ 5ê°œë§Œ ìƒì„¸ ì¶œë ¥
                print(f"\nğŸ¯ ì‹œì  {i+1}: {t}")
                print(
                    f"   ğŸ“Š NOx ì˜ˆì¸¡: mean={gp_pred_mean[i]:.3f} Â± {gp_pred_std[i]:.3f} (UCB: {gp_pred_ucb[i]:.3f})"
                )

            # PumpOptimizerë¥¼ ìœ„í•œ ì…ë ¥ ë°ì´í„° ì¤€ë¹„
            current_row = agg[agg["_time_gateway"] == t].iloc[0]

            # Hz ì¶”ì²œ ìˆ˜í–‰
            try:
                recommendation = pump_optimizer.predict_pump_hz(
                    target_nox=opt_cfg.target_nox,
                    pump_bounds=opt_cfg.pump_bounds,
                    current_oxygen=float(current_row["BR1_EO_O2_A"]),
                    current_temp=float(current_row["ICF_CCS_FG_T_1"]),
                    current_target=float(current_row["ICF_TMS_NOX_A"]),
                    p_feasible=opt_cfg.p_feasible,
                    n_candidates=opt_cfg.n_candidates,
                    round_to_int=opt_cfg.round_to_int,
                )

                # DataFrameì— ê²°ê³¼ ì €ì¥ (PumpOptimizerê°€ ì„ íƒí•œ Hzì— ëŒ€í•œ ì‹¤ì œ ì˜ˆì¸¡ê°’ ì‚¬ìš©)
                mask = agg_with_recommendations["_time_gateway"] == t
                agg_with_recommendations.loc[mask, cc.col_pred_mean] = recommendation[
                    cc.col_pred_mean
                ]
                agg_with_recommendations.loc[mask, cc.col_pred_ucb] = recommendation[
                    cc.col_pred_ucb
                ]
                agg_with_recommendations.loc[mask, cc.col_hz_out] = recommendation[
                    cc.col_hz_out
                ]
                agg_with_recommendations.loc[mask, cc.col_safety_gap] = recommendation[
                    cc.col_safety_gap
                ]

                # PumpOptimizerì˜ ê·œì¹™ í›„ì²˜ë¦¬ ì ìš©
                df_single = pd.DataFrame(
                    [
                        {
                            cc.col_datetime: t,
                            cc.col_o2: float(current_row["BR1_EO_O2_A"]),
                            cc.col_temp: float(current_row["ICF_CCS_FG_T_1"]),
                            cc.col_inner_temp: float(current_row["ICF_CCS_FG_T_1"]),
                            cc.col_outer_temp: float(current_row["ICF_SCS_FG_T_1"]),
                            cc.col_nox: float(current_row["ICF_TMS_NOX_A"]),
                            cc.col_hz_raw_out: recommendation[cc.col_hz_out],
                        }
                    ]
                )

                # ê·œì¹™ í›„ì²˜ë¦¬ ì ìš©
                df_with_rules = pump_optimizer.add_rule_columns(df_single)

                # 4ê°œ Hz ì»¬ëŸ¼ ëª¨ë‘ ì €ì¥
                agg_with_recommendations.loc[mask, cc.col_hz_raw_out] = df_with_rules[
                    cc.col_hz_raw_out
                ].iloc[0]
                agg_with_recommendations.loc[mask, cc.col_hz_init_rule] = df_with_rules[
                    cc.col_hz_init_rule
                ].iloc[0]
                agg_with_recommendations.loc[mask, cc.col_hz_full_rule] = df_with_rules[
                    cc.col_hz_full_rule
                ].iloc[0]

                if i < 5:  # ì²˜ìŒ 5ê°œë§Œ ìƒì„¸ ì¶œë ¥
                    # PumpOptimizerì—ì„œ ì„ íƒí•œ Hzì— ëŒ€í•œ ì‹¤ì œ NOx ì˜ˆì¸¡ê°’ ì¶œë ¥
                    selected_hz = df_with_rules[cc.col_hz_raw_out].iloc[0]
                    selected_nox_mean = recommendation[cc.col_pred_mean]
                    selected_nox_ucb = recommendation[cc.col_pred_ucb]
                    safety_gap = recommendation[cc.col_safety_gap]
                    print(f"   ğŸ›ï¸ Hz ì¶”ì²œ (GP): {selected_hz:.1f} Hz")
                    print(
                        f"   ğŸ“ˆ ì˜ˆì¸¡ NOx: {selected_nox_mean:.3f} (UCB: {selected_nox_ucb:.3f})"
                    )
                    print(f"   ğŸ›¡ï¸ ì•ˆì „ ì—¬ìœ : {safety_gap:.3f}")
                    print(f"   ğŸ”§ ê·œì¹™ í›„ì²˜ë¦¬ ì ìš© ì¤‘...")
                    print(
                        f"   ğŸ›ï¸ Hz ì¶”ì²œ (O2ê·œì¹™): {df_with_rules[cc.col_hz_init_rule].iloc[0]:.1f} Hz"
                    )
                    print(
                        f"   ğŸ›ï¸ Hz ì¶”ì²œ (ì „ì²´ê·œì¹™): {df_with_rules[cc.col_hz_full_rule].iloc[0]:.1f} Hz"
                    )

            except Exception as e:
                if i < 5:  # ì²˜ìŒ 5ê°œë§Œ ìƒì„¸ ì¶œë ¥
                    print(f"   âŒ Hz ì¶”ì²œ ì‹¤íŒ¨: {e}")
                # fallback Hz ì‚¬ìš©
                fallback_hz = 43.0
                mask = agg_with_recommendations["_time_gateway"] == t
                agg_with_recommendations.loc[mask, cc.col_hz_out] = fallback_hz

        print(f"\nâœ… GP ëª¨ë¸ ì˜ˆì¸¡ ì™„ë£Œ: {len(valid_times)}ê°œ ì‹œì ")

        # 7) LGBM ëª¨ë¸ ì˜ˆì¸¡ ë° Hz ì¡°ì • (ë””ë²„ê¹…ì„ ìœ„í•´ ì£¼ì„ì²˜ë¦¬)
        # print("\nğŸ§  LGBM ëª¨ë¸ ì˜ˆì¸¡ ë° Hz ì¡°ì • ì‹œì‘...")

        # # LGBM ì „ì²˜ë¦¬: ìš”ì•½í†µê³„ëŸ‰ Feature ìƒì„±
        # # [0910] LGBM ì „ì²˜ë¦¬ ì „ì— ì»¬ëŸ¼ëª… ë§¤í•‘
        # df_mapped = agg_with_recommendations.copy()
        # column_mapping = {
        #     "BR1_EO_O2_A": "br1_eo_o2_a",
        #     "ICF_CCS_FG_T_1": "icf_ccs_fg_t_1",
        #     "ICF_SCS_FG_T_1": "icf_scs_fg_t_1",
        #     "ICF_TMS_NOX_A": "icf_tms_nox_a",
        # }
        # for influx_col, config_col in column_mapping.items():
        #     if influx_col in df_mapped.columns:
        #         df_mapped[config_col] = df_mapped[influx_col]

        # # LGBM ì „ì²˜ë¦¬ (ë§¤í•‘ëœ DataFrame ì‚¬ìš©)
        # lgbm_suggested_df, lgbm_cols_x_stat = lgbm_preprocessor.make_interval_features(
        #     df_mapped
        # )

        # # LGBM ëª¨ë¸ ì„¤ì • ì—…ë°ì´íŠ¸
        # lgbm_cols_x_original = cc.lgbm_feature_columns
        # lgbm_cfg.lgbm_feature_columns_original = list(lgbm_cols_x_original)
        # lgbm_cfg.lgbm_feature_columns_summary = list(lgbm_cols_x_stat)
        # # lgbm_cfg.native_model_path = lgbm_model_path

        # # LGBM ëª¨ë¸ ì˜ˆì¸¡ ë° Hz ì¡°ì •
        # lgbm_suggested_df = lgbm_adjuster.predict_and_adjust(
        #     lgbm_suggested_df, return_flags=True
        # )

        # # LGBM ê²°ê³¼ë¥¼ ì›ë³¸ DataFrameì— ë³‘í•©
        # lgbm_result_cols = [cc.col_lgbm_db_pred_nox, cc.col_lgbm_db_hz_lgbm_adj]
        # for col in lgbm_result_cols:
        #     if col in lgbm_suggested_df.columns:
        #         agg_with_recommendations[col] = lgbm_suggested_df[col].values

        # [0910] col_hz_final ì„¤ì • (LGBM ë¹„í™œì„±í™” ì‹œ GP ì „ì²´ ê·œì¹™ ê²°ê³¼ ì‚¬ìš©)
        agg_with_recommendations[cc.col_hz_final] = agg_with_recommendations[
            cc.col_hz_full_rule
        ]

        print("â„¹ï¸ LGBM ëª¨ë¸ ì˜ˆì¸¡ ë¹„í™œì„±í™” (ë””ë²„ê¹… ëª¨ë“œ)")

        # ìµœì¢… ê²°ê³¼ ì¶œë ¥ (ì²˜ìŒ 10ê°œ í–‰ë§Œ)
        print("\nğŸ“Š ìµœì¢… ì¶”ì²œ ê²°ê³¼ (ì²˜ìŒ 10ê°œ í–‰):")
        result_cols = [
            "_time_gateway",
            cc.col_pred_mean,
            cc.col_pred_ucb,
            cc.col_hz_raw_out,  # act_snr_pmp_bo_1 (GP ê²°ê³¼)
            cc.col_hz_init_rule,  # act_snr_pmp_bo_2 (O2 ê·œì¹™ ì ìš©)
            cc.col_hz_full_rule,  # act_snr_pmp_bo_3 (O2 + ë™ì  ê·œì¹™)
            cc.col_safety_gap,
        ]

        # LGBM ì»¬ëŸ¼ ì¶”ê°€ (ë””ë²„ê¹… ëª¨ë“œì—ì„œëŠ” ë¹„í™œì„±í™”)
        # if cc.col_lgbm_db_pred_nox in agg_with_recommendations.columns:
        #     result_cols.append(cc.col_lgbm_db_pred_nox)
        # if cc.col_lgbm_db_hz_lgbm_adj in agg_with_recommendations.columns:
        #     result_cols.append(cc.col_lgbm_db_hz_lgbm_adj)

        # [0910] col_hz_final ì¶”ê°€ (ìµœì¢… Hz ì¶”ì²œ ê°’)
        if cc.col_hz_final in agg_with_recommendations.columns:
            result_cols.append(cc.col_hz_final)

        available_cols = [
            c for c in result_cols if c in agg_with_recommendations.columns
        ]
        print(agg_with_recommendations[available_cols].head(10))

    else:
        print("âš ï¸ ì˜ˆì¸¡ ê°€ëŠ¥í•œ(ê²°ì¸¡ ì—†ëŠ”) 5ì´ˆ êµ¬ê°„ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ê²°ì¸¡ìœ¼ë¡œ ì œì™¸ëœ êµ¬ê°„ì€ NaNìœ¼ë¡œ í‘œì‹œ
    for t in invalid_times:
        print(f"âšª {t} â†’ NOx mean=NaN (insufficient data)")

    print("\nğŸ“Œ ìš”ì•½")
    print("- RUN_ID:", run_id)
    print("- GP ëª¨ë¸ ê²½ë¡œ:", model_file)
    print("- LGBM ëª¨ë¸ ê²½ë¡œ:", lgbm_model_path, "(ë¹„í™œì„±í™”)")
    print("- ì…ë ¥ ìš”ì•½ í–‰ ìˆ˜:", len(agg))
    print("- GP ëª¨ë¸ ì˜ˆì¸¡ ì™„ë£Œ: PumpOptimizer í™œìš©")
    print("- LGBM ëª¨ë¸ ì˜ˆì¸¡: ë¹„í™œì„±í™” (ë””ë²„ê¹… ëª¨ë“œ)")


if __name__ == "__main__":
    main()
